{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공뉴런 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"https://www.researchgate.net/publication/320270458/figure/fig1/AS:551197154254848@1508427050805/Mathematical-model-of-artificial-neuron.png\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: [ResearchGate](https://www.slideshare.net/jbhuang/lecture-29-convolutional-neural-networks-computer-vision-spring2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주의\n",
    "* 인공뉴런이란 표현이 마치 인간의 뇌처럼 작동한다는 오해를 불러 일으킴.\n",
    "* 하지만 인공뉴련과 인간이 뇌는 아무런 상관이 없음.\n",
    "* 인공뉴런은 하나의 수학적 모델에 불과함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력값(x)과 가중치 벡터(w)의 선형 조합\n",
    "\n",
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/sum01.png\" width=\"50%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/sum02.png\" width=\"70%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 활성화함수 예제: 로지스틱 회귀(Logistic Regression)\n",
    "\n",
    "\n",
    "* 결정함수: $ g(y) = \\begin{cases} 1 & y \\ge 0 \\text{인 경우,}\\\\ 0 & y < 0\\text{인 경우.} \\end{cases} $\n",
    "\n",
    "* 활성화 함수: $\\varphi(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "\n",
    "* 목적함수: 비용함수(loss function)\n",
    "\n",
    "    $$J(w) = \\sum_i \\large [ -y^{(i)} \\log (\\varphi(z^{(i)})) - (1 - y^{(i)}) \\log (1 - \\varphi(z^{(i)})) \\large ]$$\n",
    "    \n",
    "    $$z^{(i)} = w^T x^{(i)}$$\n",
    "    \n",
    "    단, $x^{(i)}$는 $i$ 번째 샘플임.\n",
    "\n",
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"http://rasbt.github.io/mlxtend/user_guide/classifier/LogisticRegression_files/logistic_regression_schematic.png\"  width=\"80%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: [MLxtend](http://rasbt.github.io/mlxtend/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습최적화\n",
    "\n",
    "#### 학습최적화 대상: 목적함수\n",
    "\n",
    "학습과정 동안 최적화하기 위해 정의된 함수를 목적함수(object function)이라 부른다.\n",
    "학습모델에 따라 목적함수의 정의가 달라진다.\n",
    "\n",
    "#### 학습 최적화\n",
    "\n",
    "목적함수의 최적화를 이루어 가는 과정을 가리키며, 목적함수의 최적화를 위해 가중치 벡터의 값을 효율적으로 변화시키는 머신러닝의 과정이 주요 과제이다. \n",
    "\n",
    "#### 최적화\n",
    "\n",
    "* 함수의 값이 최대 또는 최소가 되게 하는 입력값을 찾는 과정\n",
    "* 보통 경사하강법 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사하강법\n",
    "\n",
    "도함수의 반대 방향으로 조금씩 이동하며 최소점 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/gda-problems01.png\" width=\"60%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: [Jaehyeong's DS](https://jaehyeongan.github.io/2019/04/23/경사하강법-Gradient-Descent/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제: 비용함수(loss function) 활용\n",
    "\n",
    "$$J(w) = \\frac{1}{2} \\sum_i \\large (y^{(i)} - \\varphi(z^{(i)}) \\large)^2$$\n",
    "\n",
    "$$z^{(i)} = w^T x^{(i)}$$\n",
    "\n",
    "* $x^{(i)}$는 $i$ 번째 샘플임.\n",
    "* $w$가 2차원 벡터\n",
    "* $J(w)$의 그래프는 3차원 곡면\n",
    "* $J(w)$가 최소가 되는 $w$ 찾기\n",
    "\n",
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/convex_nonconvex.jpg\" width=\"70%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: [Jaehyeong's DS](https://jaehyeongan.github.io/2019/04/23/경사하강법-Gradient-Descent/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝\n",
    "\n",
    "* 딥러닝: 인공신경망을 여러 겹으로 쌓은 모델\n",
    "* 가장 간단한 신경망: 퍼셉트론 모델, 선형 회귀 모델, 로지스틱 회귀 모델, SVM 모델 등\n",
    "* 이미지, 음성, 텍스트 등 정형화되지 못한 데이터와 관련된 분야의 어려운 문제를 해결하기 위해 사용\n",
    "* 반면에 일반적인 머신러닝은 데이터가 비교적 잘 정리된 데이터에 대해 유용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 심층 인공신경망\n",
    "* 하나 이상의 은닉층(hidden layers)을 가진 네트워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 은닉층 1개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/neuralnet_mlp_1.png\" width=\"80%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: [MLxtend](http://rasbt.github.io/mlxtend/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 은닉층 3개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/mlp01.png\" width=\"70%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: 그림 출처: [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap6.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 은닉층 12개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/mlp01a.png\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: 그림 출처: [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap6.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱 신경망(Convolutional neural network)\n",
    "\n",
    "사물인식이 부분적으로 나뉘어 인식된다는 점에 착안한 심층 인공심경망 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/convolutional01.png\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap6.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KSH 논문\n",
    "* ImageNet classification with deep convolutional neural networks\n",
    "* 저자: Krizhevsky, Sutskever and Hinton\n",
    "* 연도: 2012\n",
    "* 주요 결과\n",
    "    * 이미지넷의 '대규모 이미지 인식 대회'에서 기존의 기록을 혁신적으로 갱신함\n",
    "    * 기존 정확도: 73.8%\n",
    "    * 갱신 기록: 84.7%\n",
    "* 사용 심층신경망: 합성곱 신경망 응용\n",
    "    * 은닉층 7개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/mlp02.jpg\" width=\"90%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap6.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대규모 이미지 인식 대회(the ImageNet Large-Scale Visual Recognition Challenge, ILSVRC)\n",
    "\n",
    "* 이미지: 120만개\n",
    "* 이미지 범주: 1,000개\n",
    "* 동일 범주의 이미지가 중복되게 섞여 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/convolutional02.png\" width=\"90%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: [NVIDEA Developer Blog](https://devblogs.nvidia.com/mocha-jl-deep-learning-julia/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ILSVRC 기록 변천사\n",
    "\n",
    "* 2015년부터 사람보다 이미지 구분 및 분석을 잘함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/imagenet01.png\" width=\"70%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: [NVIDEA Developer Blog](https://devblogs.nvidia.com/mocha-jl-deep-learning-julia/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/backpropagation.png\" width=\"70%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: [NVIDEA Developer Blog](https://devblogs.nvidia.com/inference-next-step-gpu-accelerated-deep-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 역전파 문제\n",
    "\n",
    "* 층에서 층으로의 오차 전달 어려움.\n",
    "* 역전파가 전달될 수록 오차의 의미가 흐릿해짐.\n",
    "* 이유: 너무 복잡 (사실 잘 모름)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/backpropagation04.png\">\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"../images/backpropagation03.png\" width=\"70%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: 머신러닝 교과서 with 파이썬, 싸이킷런, 텐서플로 (라시카, 미자지리 지음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 역전파 문제 해결\n",
    "\n",
    "* $W$의 초기값을 잘 잡으면 됨.\n",
    "* 초기값을 어떻게 잘 잡을 수 있는지는 일반적으로 알려져 있지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝/딥러닝에 관심을 가져야 하는 이유\n",
    "\n",
    "전공에 상관없이\n",
    "\n",
    "* 데이터를 다루는가?\n",
    "* 무언가를 팔고 싶은가?\n",
    "* 어떤 사업을 하는가?\n",
    "\n",
    "등 모든 경우에 상관이 있으며 머신러닝/딥러닝을 알면 큰 도움이 될 것임.\n",
    "\n",
    "#### 주요 활용 예제\n",
    "\n",
    "* 구글 검색엔진\n",
    "* 유튜브 자막 캡션\n",
    "* 넷플릭스/아마존 추천 기능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"../images/googlesearch01.png\" width=\"70%\">\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"../images/youtubecaption.png\">\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"../images/netflixrecommendation.png\" width=\"70%\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "그림 출처: 머신러닝 교과서 with 파이썬, 싸이킷런, 텐서플로 (라시카, 미자지리 지음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 머신러닝 관련 기사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [손님 어디 있는지 AI가 먼저 안다…\"빅데이터가 돈\" (MBC 뉴스데스크)](http://imnews.imbc.com/replay/2019/nwdesk/article/5634312_24634.html?menuid=nwdesk)\n",
    "* [2019년, ‘머신러닝’에 더욱 주목해야 하는 이유(FastCampus)](http://media.fastcampus.co.kr/knowledge/data-science/ai2019/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 실전 예제 따라하기\n",
    "\n",
    "* [다층 인공 신경망을 밑바닥부터 구현(구글 코랩)](https://colab.research.google.com/github/rickiepark/python-machine-learning-book-2nd-edition/blob/master/code/ch12/ch12.ipynb#scrollTo=fzWbfHw4bgIO)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.최소한의도구로시작합니다.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
